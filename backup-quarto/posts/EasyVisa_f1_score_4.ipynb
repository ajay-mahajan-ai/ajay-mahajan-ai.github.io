{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8560690",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Easy Visa\"\n",
    "date: 2025-08-05\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xJPSrx6D-Lft",
   "metadata": {
    "id": "xJPSrx6D-Lft"
   },
   "source": [
    "<center><p float=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n",
    "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
    "</p></center>\n",
    "\n",
    "<center><font size=10>Artificial Intelligence and Machine Learning</font></center>\n",
    "<center><font size=6>Advanced Machine Learning - Project Debrief</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wv_XHSCN-Yl_",
   "metadata": {
    "id": "wv_XHSCN-Yl_"
   },
   "source": [
    "<center><img src=\"https://images.pexels.com/photos/7235894/pexels-photo-7235894.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2\" width=\"800\" height=\"500\"></center>\n",
    "\n",
    "<center><font size=6>Visa Approval Facilitation</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yZvo8CHcetWN",
   "metadata": {
    "id": "yZvo8CHcetWN"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oMq62cFvNi8j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMq62cFvNi8j",
    "outputId": "03cbfa4f-25f9-49d2-f0f6-bc93d7a6fd4f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-shanghai",
   "metadata": {
    "id": "empty-shanghai"
   },
   "source": [
    "### Context:\n",
    "\n",
    "Business communities in the United States are facing high demand for human resources, but one of the constant challenges is identifying and attracting the right talent, which is perhaps the most important element in remaining competitive. Companies in the United States look for hard-working, talented, and qualified individuals both locally as well as abroad.\n",
    "\n",
    "The Immigration and Nationality Act (INA) of the US permits foreign workers to come to the United States to work on either a temporary or permanent basis. The act also protects US workers against adverse impacts on their wages or working conditions by ensuring US employers' compliance with statutory requirements when they hire foreign workers to fill workforce shortages. The immigration programs are administered by the Office of Foreign Labor Certification (OFLC).\n",
    "\n",
    "OFLC processes job certification applications for employers seeking to bring foreign workers into the United States and grants certifications in those cases where employers can demonstrate that there are not sufficient US workers available to perform the work at wages that meet or exceed the wage paid for the occupation in the area of intended employment.\n",
    "\n",
    "### Objective:\n",
    "\n",
    "In FY 2016, the OFLC processed 775,979 employer applications for 1,699,957 positions for temporary and permanent labor certifications. This was a nine percent increase in the overall number of processed applications from the previous year. The process of reviewing every case is becoming a tedious task as the number of applicants is increasing every year.\n",
    "\n",
    "The increasing number of applicants every year calls for a Machine Learning based solution that can help in shortlisting the candidates having higher chances of VISA approval. OFLC has hired the firm EasyVisa for data-driven solutions. You as a data  scientist at EasyVisa have to analyze the data provided and, with the help of a classification model:\n",
    "\n",
    "* Facilitate the process of visa approvals.\n",
    "* Recommend a suitable profile for the applicants for whom the visa should be certified or denied based on the drivers that significantly influence the case status.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The data contains the different attributes of employee and the employer. The detailed data dictionary is given below.\n",
    "\n",
    "* case_id: ID of each visa application\n",
    "* continent: Information of continent the employee\n",
    "* education_of_employee: Information of education of the employee\n",
    "* has_job_experience: Does the employee has any job experience? Y= Yes; N = No\n",
    "* requires_job_training: Does the employee require any job training? Y = Yes; N = No\n",
    "* no_of_employees: Number of employees in the employer's company\n",
    "* yr_of_estab: Year in which the employer's company was established\n",
    "* region_of_employment: Information of foreign worker's intended region of employment in the US.\n",
    "* prevailing_wage:  Average wage paid to similarly employed workers in a specific occupation in the area of intended employment. The purpose of the prevailing wage is to ensure that the foreign worker is not underpaid compared to other workers offering the same or similar service in the same area of employment.\n",
    "* unit_of_wage: Unit of prevailing wage. Values include Hourly, Weekly, Monthly, and Yearly.\n",
    "* full_time_position: Is the position of work full-time? Y = Full Time Position; N = Part Time Position\n",
    "* case_status:  Flag indicating if the Visa was certified or denied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lm7obbsV_RUT",
   "metadata": {
    "id": "Lm7obbsV_RUT"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6IOeGuQTMQXd",
   "metadata": {
    "id": "6IOeGuQTMQXd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.11 are installed in '/Users/ajaymahajan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-expr 1.1.13 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing the libraries with the specified version.\n",
    "!pip install numpy==1.25.2 pandas==1.5.3 scikit-learn==1.5.2 matplotlib==3.7.1 seaborn==0.13.1 xgboost==2.0.3 -q --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OS2VAv465IZa",
   "metadata": {
    "id": "OS2VAv465IZa"
   },
   "source": [
    "**Note**: *After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-maple",
   "metadata": {
    "id": "canadian-maple"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Library to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "# libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "\n",
    "# Libraries different ensemble classifiers\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Libraries to get different metric scores\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# To tune different models\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-passion",
   "metadata": {
    "id": "thorough-passion"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q_MqHR8tN8mz",
   "metadata": {
    "id": "q_MqHR8tN8mz"
   },
   "outputs": [],
   "source": [
    "# loading data into a pandas dataframe\n",
    "easy_visa_data = pd.read_csv(\"/content/drive/MyDrive/EasyVisa.csv\")\n",
    "\n",
    "# copy the original data set.\n",
    "data = easy_visa_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mq-1s9p-_aKl",
   "metadata": {
    "id": "mq-1s9p-_aKl"
   },
   "source": [
    "## Overview of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-wrist",
   "metadata": {
    "id": "aboriginal-wrist"
   },
   "source": [
    "#### View the first and last 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cVzRbi7oN6br",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "cVzRbi7oN6br",
    "outputId": "6076a5a8-e3dd-4d09-edc0-1f46e96a0439"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3SoSr3U_QUYC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "3SoSr3U_QUYC",
    "outputId": "fb062ac9-c445-44ee-da3f-b524b6853016"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-camel",
   "metadata": {
    "id": "accessory-camel"
   },
   "source": [
    "#### Understand the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ym8ApC21N64n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym8ApC21N64n",
    "outputId": "7a35e996-f743-4e2a-adc5-4fd9bd471816"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4h48S4hvWNdy",
   "metadata": {
    "id": "4h48S4hvWNdy"
   },
   "source": [
    "There are 25480 rows and 12 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-berkeley",
   "metadata": {
    "id": "assigned-berkeley"
   },
   "source": [
    "#### Check the data types of the columns for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ekk0QEpXN7im",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekk0QEpXN7im",
    "outputId": "2c455453-3eeb-483e-80d2-14a7fdeaf61c"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nr-PcbsSWgkD",
   "metadata": {
    "id": "nr-PcbsSWgkD"
   },
   "source": [
    "There are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PN3nbAGqTMs0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PN3nbAGqTMs0",
    "outputId": "5983345c-24cd-4326-bc8f-1e0368d5e269"
   },
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WGD1an81WlI5",
   "metadata": {
    "id": "WGD1an81WlI5"
   },
   "source": [
    "There are no duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lB-RzGyOTlo5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "lB-RzGyOTlo5",
    "outputId": "9fc4b204-8c60-42bd-ea28-e881cac37bec"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RQ77DSDUWpoq",
   "metadata": {
    "id": "RQ77DSDUWpoq"
   },
   "source": [
    "No NULL values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZEhOblKGGR9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEhOblKGGR9g",
    "outputId": "a5bfaaf8-282f-4d64-a7b9-3003be9bde20"
   },
   "outputs": [],
   "source": [
    "data.case_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w_a6heQAXGTK",
   "metadata": {
    "id": "w_a6heQAXGTK"
   },
   "source": [
    "caes_id is unique per row and can safely be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpXFibDCYb6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "wpXFibDCYb6a",
    "outputId": "c673dbf1-f4aa-4158-e424-9e1ea01b8051"
   },
   "outputs": [],
   "source": [
    "# ID contains only unique values so we will drop it\n",
    "data.drop(columns=['case_id'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-horizontal",
   "metadata": {
    "id": "standing-horizontal"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-venue",
   "metadata": {
    "id": "american-venue"
   },
   "source": [
    "#### Let's check the statistical summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PsJ9MaHRN4U5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "PsJ9MaHRN4U5",
    "outputId": "ba4325b2-6c3a-415b-ce8d-0b52fe7add9d"
   },
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nKZPt2lrYgGp",
   "metadata": {
    "id": "nKZPt2lrYgGp"
   },
   "source": [
    "**no_of_employees:**\n",
    "* Mean: 5,667 employees per company on average.\n",
    "* Median (50%): 2,109 — way lower than mean -> positively skewed (long tail to the right).\n",
    "* Max: 602,069 - extreme outlier (very large company).\n",
    "\n",
    "**yr_of_estab (Year of Establishment)**\n",
    "* Mean: 1979; Median: 1997 -> suggests many newer companies, but some very old ones.\n",
    "* Min: 1800 — this is unusually early, likely a data entry error, may need further investigation.\n",
    "* Max: 2016 - recent establishment years.\n",
    "* Most companies are relatively modern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-timing",
   "metadata": {
    "id": "competent-timing"
   },
   "source": [
    "#### Fixing the negative values in number of employees columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ltjRQiBN40d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ltjRQiBN40d",
    "outputId": "9be8cb92-7694-4ec3-f822-97a690c6d2cb"
   },
   "outputs": [],
   "source": [
    "(data['no_of_employees'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UMbQN4RYXsCE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMbQN4RYXsCE",
    "outputId": "3623e299-340b-48a7-9dd6-4e6b50c008a2"
   },
   "outputs": [],
   "source": [
    "data['no_of_employees'] = data['no_of_employees'].abs()\n",
    "(data['no_of_employees'] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wGDFZVfOXgqS",
   "metadata": {
    "id": "wGDFZVfOXgqS"
   },
   "source": [
    "Correct the negetive value by taking the absolute value and re-check for remaining negetives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-bookmark",
   "metadata": {
    "id": "cutting-bookmark"
   },
   "source": [
    "#### Let's check the count of each unique category in each of the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tjT97Rc9N5SC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjT97Rc9N5SC",
    "outputId": "d2305fc0-b09e-4f05-b961-465254cb188c"
   },
   "outputs": [],
   "source": [
    "# Making a list of all catrgorical variables\n",
    "cat_col = list(data.select_dtypes(\"object\").columns)\n",
    "\n",
    "# Printing number of count of each unique value in each column\n",
    "for column in cat_col:\n",
    "    print(data[column].value_counts())\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-christian",
   "metadata": {
    "id": "wooden-christian"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-springfield",
   "metadata": {
    "id": "superb-springfield"
   },
   "outputs": [],
   "source": [
    "def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (15,10))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R59VWoa5Wdbx",
   "metadata": {
    "id": "R59VWoa5Wdbx"
   },
   "outputs": [],
   "source": [
    "# function to create labeled barplots\n",
    "\n",
    "\n",
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-command",
   "metadata": {
    "id": "editorial-command"
   },
   "source": [
    "#### Observations on education of employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8PjkMDRiN1lA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "8PjkMDRiN1lA",
    "outputId": "8b49b367-6f3d-40a7-b843-61294e41571f"
   },
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"education_of_employee\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4nE-_PWjrI4",
   "metadata": {
    "id": "n4nE-_PWjrI4"
   },
   "source": [
    "* The majority of employees **(~78%)** have either a **Bachelor's or Master's** degree, making this the dominant education range.\n",
    "* **Doctorate holders** are the smallest group (8.6%), which may reflect the specialized nature of such roles or fewer applicants.\n",
    "* **High School education** accounts for 13.4% — significantly lower than higher education categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-burlington",
   "metadata": {
    "id": "attempted-burlington"
   },
   "source": [
    "#### Observations on region of employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_eEpcxf4N2GY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "_eEpcxf4N2GY",
    "outputId": "45944498-3437-4dfe-f6c0-b2a795a08298"
   },
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"region_of_employment\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2Ogrh175koI1",
   "metadata": {
    "id": "2Ogrh175koI1"
   },
   "source": [
    "* The Northeast has the highest share of visa applicants, closely followed by the South and West.\n",
    "* The Island region has a very small applicant base.\n",
    "* Midwest lags behind in volume, possibly due to fewer employer sponsorships or tech hubs compared to coasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-kidney",
   "metadata": {
    "id": "forbidden-kidney"
   },
   "source": [
    "#### Observations on job experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W2OyS2efN2mw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "W2OyS2efN2mw",
    "outputId": "68e6f026-f14a-4fe7-babf-f03fbca4f7f8"
   },
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"has_job_experience\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgGVDsbNk5uy",
   "metadata": {
    "id": "xgGVDsbNk5uy"
   },
   "source": [
    "* A majority of applicants (58.1%) have prior job experience, which could positively influence their visa approval chances.\n",
    "* Nearly 42% are inexperienced, possibly recent graduates or fresh entrants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-surrey",
   "metadata": {
    "id": "stunning-surrey"
   },
   "source": [
    "#### Observations on case status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0kaXC-PhN3IU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "0kaXC-PhN3IU",
    "outputId": "7f537e05-0de1-4bd1-a0f9-55b7994ac32c"
   },
   "outputs": [],
   "source": [
    "labeled_barplot(data, \"case_status\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evM345wVlI0V",
   "metadata": {
    "id": "evM345wVlI0V"
   },
   "source": [
    "* Two-thirds of applications are approved, indicating a favorable environment for most applicants.\n",
    "* Still, 1 in 3 applications gets denied, suggesting room for improvement in eligibility, documentation, or employer sponsorship strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-aging",
   "metadata": {
    "id": "equivalent-aging"
   },
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-convertible",
   "metadata": {
    "id": "blond-convertible"
   },
   "source": [
    "**Creating functions that will help us with further analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-recipient",
   "metadata": {
    "id": "adaptive-recipient"
   },
   "outputs": [],
   "source": [
    "### function to plot distributions wrt target\n",
    "\n",
    "\n",
    "def distribution_plot_wrt_target(data, predictor, target):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    target_uniq = data[target].unique()\n",
    "\n",
    "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[0]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 0],\n",
    "        color=\"teal\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
    "    sns.histplot(\n",
    "        data=data[data[target] == target_uniq[1]],\n",
    "        x=predictor,\n",
    "        kde=True,\n",
    "        ax=axs[0, 1],\n",
    "        color=\"orange\",\n",
    "        stat=\"density\",\n",
    "    )\n",
    "\n",
    "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
    "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
    "\n",
    "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
    "    sns.boxplot(\n",
    "        data=data,\n",
    "        x=target,\n",
    "        y=predictor,\n",
    "        ax=axs[1, 1],\n",
    "        showfliers=False,\n",
    "        palette=\"gist_rainbow\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-sheriff",
   "metadata": {
    "id": "third-sheriff"
   },
   "outputs": [],
   "source": [
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 5, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\", frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UNKq05pIa1La",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "UNKq05pIa1La",
    "outputId": "5bef1221-9305-4331-8bdf-8236ca1e7845"
   },
   "outputs": [],
   "source": [
    "cols_list = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "## find the correlation between the variables\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(\n",
    "    data[cols_list].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UIyt8xuttImo",
   "metadata": {
    "id": "UIyt8xuttImo"
   },
   "source": [
    "There appears to be no correlation within independent features of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-excuse",
   "metadata": {
    "id": "dressed-excuse"
   },
   "source": [
    "#### Those with higher education may want to travel abroad for a well-paid job. Let's find out if education has any impact on visa certification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VtZ978lDNxfu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "VtZ978lDNxfu",
    "outputId": "eb945af0-1f40-4acc-b7c1-04e595f3624b"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"education_of_employee\", \"case_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5YtP2IfBljC2",
   "metadata": {
    "id": "5YtP2IfBljC2"
   },
   "source": [
    "* The higher the education level, the greater the visa approval rate.\n",
    "* Applicants with only a High School education face a much higher rejection rate (~65%).\n",
    "* Doctorate holders have the highest approval rate (~87%), followed closely by Master’s degree applicants.\n",
    "* This chart clearly shows that education is a strong predictor of visa certification success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-current",
   "metadata": {
    "id": "attended-current"
   },
   "source": [
    "#### Lets' similarly check for the continents and find out how the visa status vary across different continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evbNlj4XNyBe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "evbNlj4XNyBe",
    "outputId": "a0210c19-2904-490f-e3ba-81a47f9120f7"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"continent\", \"case_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ESy4VlyGl8n9",
   "metadata": {
    "id": "ESy4VlyGl8n9"
   },
   "source": [
    "* Europe and Africa show the highest approval rates, making them favorable continents in terms of visa outcomes.\n",
    "* Asia and Oceania are more middle-ground, with balanced approval/denial rates.\n",
    "* South America has the lowest certification rate (~58%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-decrease",
   "metadata": {
    "id": "macro-decrease"
   },
   "source": [
    "#### Experienced professionals might look abroad for opportunities to improve their lifestyles and career development. Let's see if having work experience has any influence over visa certification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcf_oGNyfo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "d3fcf_oGNyfo",
    "outputId": "bdf26ed5-4763-4c50-d5ab-0c4be1c03910"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"has_job_experience\", \"case_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tNLP0j1LmPpr",
   "metadata": {
    "id": "tNLP0j1LmPpr"
   },
   "source": [
    "* Applicants with job experience are much more likely to be certified (~75%) compared to those without.\n",
    "* Lack of experience increases denial risk, with nearly half of inexperienced applicants getting denied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-kansas",
   "metadata": {
    "id": "changing-kansas"
   },
   "source": [
    "#### Checking if the prevailing wage is similar across all the regions of the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0FYdlpG5NzEe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "0FYdlpG5NzEe",
    "outputId": "a25e2ce4-fa16-479b-d244-783ac75573a8"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x=\"region_of_employment\", y=\"prevailing_wage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CbRVwurbmgpL",
   "metadata": {
    "id": "CbRVwurbmgpL"
   },
   "source": [
    "* Midwest and Island regions offer the highest median prevailing wages, despite having fewer applicants.\n",
    "* West and Northeast, despite being tech hubs, show lower median wages, possibly due to a higher number of entry-level or lower-paying positions.\n",
    "* All regions show a large number of outliers, indicating presence of high-paying roles (e.g., tech, specialized roles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-bacteria",
   "metadata": {
    "id": "lesser-bacteria"
   },
   "source": [
    "#### The US government has established a prevailing wage to protect local talent and foreign workers. Let's analyze the data and see if the visa status changes with the prevailing wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HIr2VsTGNzhA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HIr2VsTGNzhA",
    "outputId": "bafc5ceb-b884-4cca-e89c-df00446ccdc4"
   },
   "outputs": [],
   "source": [
    "distribution_plot_wrt_target(data, \"prevailing_wage\", \"case_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fDXpyKainYxh",
   "metadata": {
    "id": "fDXpyKainYxh"
   },
   "source": [
    "* Most denied cases cluster at lower wages.\n",
    "* A visible right-skewed distribution — higher wages are rare for denials.\n",
    "* Certified applications tend to have higher prevailing wages overall.\n",
    "* The density peaks around $70,000–$90,000, compared to denials peaking closer to $30,000–$50,000.\n",
    "\n",
    "**With Outliers**\n",
    "* Certified applications have a higher median wage than denied ones.\n",
    "* Certified wages also show a broader upper range, with more high-wage outliers.\n",
    "\n",
    "**Without Outliers**\n",
    "* Even after removing outliers, Certified cases still have slightly higher median and upper quartile wages, reinforcing the positive relationship between wage and approval likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZHUTf6qn11e",
   "metadata": {
    "id": "qZHUTf6qn11e"
   },
   "source": [
    "**Conclusion:**\n",
    "* Higher prevailing wage is positively correlated with visa certification.\n",
    "* Applicants with lower wages are more likely to be denied.\n",
    "* Wage can be a strong predictive feature for classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-asthma",
   "metadata": {
    "id": "suspected-asthma"
   },
   "source": [
    "#### The prevailing wage has different units (Hourly, Weekly, etc). Let's find out if it has any impact on visa applications getting certified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KgXcBCf0N0IA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "KgXcBCf0N0IA",
    "outputId": "27e5afd6-1c0b-4a5f-e929-b9a3ef5498c6"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"unit_of_wage\", \"case_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AnJhpLCwoJH-",
   "metadata": {
    "id": "AnJhpLCwoJH-"
   },
   "source": [
    "* Yearly wage entries have the highest certification rates — likely linked to full-time, salaried positions.\n",
    "* Hourly wages show the lowest approval rate (~35%), suggesting that jobs paid by the hour (e.g., part-time or lower-skill roles) may be viewed as less favorable.\n",
    "* Monthly and weekly wages fall in the middle, with moderate certification rates.\n",
    "* Unit of wage is a meaningful indicator in visa decision outcomes.\n",
    "* Yearly wage offers the strongest signal for visa success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qBWlk20UBUAx",
   "metadata": {
    "id": "qBWlk20UBUAx"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-association",
   "metadata": {
    "id": "allied-association"
   },
   "source": [
    "### Outlier Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_N9mGF2kdikb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "_N9mGF2kdikb",
    "outputId": "6124aa92-550e-4e37-c7ee-9a3b1dd7240e"
   },
   "outputs": [],
   "source": [
    "# outlier detection using boxplot\n",
    "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "for i, variable in enumerate(numeric_columns):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.boxplot(data[variable], whis=1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SN62dkx-oq2V",
   "metadata": {
    "id": "SN62dkx-oq2V"
   },
   "source": [
    "* All three features contain significant outliers.\n",
    "* Consider using robust scaling, log transformations, or capping/flooring outliers for preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-independence",
   "metadata": {
    "id": "flexible-independence"
   },
   "source": [
    "### Data Preparation for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K30uo_4Pd4Zh",
   "metadata": {
    "id": "K30uo_4Pd4Zh"
   },
   "outputs": [],
   "source": [
    "data[\"case_status\"] = data[\"case_status\"].apply(lambda x: 1 if x == \"Certified\" else 0)\n",
    "\n",
    "X = data.drop(\"case_status\", axis=1)\n",
    "y = data[\"case_status\"]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, test_size=0.1, random_state=1, stratify=y_val\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AUugPZqweHcP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUugPZqweHcP",
    "outputId": "70de8fd2-d378-4966-d52f-01d3807d01c4"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of Training set : \", X_train.shape)\n",
    "print(\"Shape of Validation set : \", X_val.shape)\n",
    "print(\"Shape of test set : \", X_test.shape)\n",
    "print(\"Percentage of classes in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"Percentage of classes in validation set:\")\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(\"Percentage of classes in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dr7q6-dbfiQB",
   "metadata": {
    "id": "dr7q6-dbfiQB"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrlw9AVcqk37",
   "metadata": {
    "id": "rrlw9AVcqk37"
   },
   "source": [
    "### Model Evaluation Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dQgDunSMensu",
   "metadata": {
    "id": "dQgDunSMensu"
   },
   "source": [
    "* Thge Model can make wrong predictions as:\n",
    "1. Model predicts the visa application will get certified for the applications that should get denied.\n",
    "2. Model predicts the visa application will get denied for the applications that should get certified.\n",
    "* Both the cases are important so we can use F1 score as the metric for evaluating the model. Greater the F1 score higher are the chances of minimizing False Negetives and False Positives.\n",
    "* We will use balanced classs weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-database",
   "metadata": {
    "id": "mexican-database"
   },
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "\n",
    "\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1,},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-topic",
   "metadata": {
    "id": "recreational-topic"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    To plot the confusion_matrix with percentages\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(predictors)\n",
    "    cm = confusion_matrix(target, y_pred)\n",
    "    labels = np.asarray(\n",
    "        [\n",
    "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
    "            for item in cm.flatten()\n",
    "        ]\n",
    "    ).reshape(2, 2)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0QZZoxoDcoDm",
   "metadata": {
    "id": "0QZZoxoDcoDm"
   },
   "source": [
    "#### Defining scorer to be used for cross-validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zxnii_qkeveb",
   "metadata": {
    "id": "zxnii_qkeveb"
   },
   "outputs": [],
   "source": [
    "scorer = metrics.make_scorer(metrics.f1_score) ## define the metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XWoHuUpjbp0_",
   "metadata": {
    "id": "XWoHuUpjbp0_"
   },
   "source": [
    "**We are now done with pre-processing and evaluation criterion, so let's start building the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fI98GOV0pTY",
   "metadata": {
    "id": "4fI98GOV0pTY"
   },
   "source": [
    "### Model building with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jt6DVGr9e8Q3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt6DVGr9e8Q3",
    "outputId": "b60a573d-c2fd-4c17-a38e-f37e68cd171e"
   },
   "outputs": [],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "\n",
    "results1 = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\nCross-Validation performance on training dataset:\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    cv_result = cross_val_score(estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold)\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\nValidation Performance:\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = f1_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HKhXlsLSfoC1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "HKhXlsLSfoC1",
    "outputId": "ec474f99-555d-47dc-9381-fd597ab4bf7f"
   },
   "outputs": [],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y6fLPLJ_pqoV",
   "metadata": {
    "id": "y6fLPLJ_pqoV"
   },
   "source": [
    "* **GBM outperforms** all other models in terms of both median performance and consistency (tight spread).\n",
    "* **Ensemble methods** (GBM, AdaBoost, XGBoost) clearly outperform individual models like dtree and Bagging.\n",
    "* **Decision Tree** not only underperforms but also has inconsistent results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C91_6Swtbp1A",
   "metadata": {
    "id": "C91_6Swtbp1A"
   },
   "source": [
    "### Model Building with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BKIusXO4f28f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKIusXO4f28f",
    "outputId": "2fde2fe7-33bd-44dd-dbc6-24130ce92dc0"
   },
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "# Synthetic Minority Over Sampling Technique\n",
    "sm = SMOTE(sampling_strategy=1.0, k_neighbors=5, random_state=1) ## set the k-nearest neighbors and sampling strategy\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_over == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_over == 0)))\n",
    "\n",
    "\n",
    "print(\"After OverSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
    "print(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NBwnj9IagKcF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBwnj9IagKcF",
    "outputId": "5d664920-305a-442c-9c91-c00bb6e54237"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "\n",
    "results1 = []\n",
    "names = []\n",
    "\n",
    "print(\"\\nCross-Validation performance on training dataset:\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\n",
    "    )\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\nValidation Performance:\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_over, y_train_over)\n",
    "    scores = f1_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E2x7z7kTgfMa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "E2x7z7kTgfMa",
    "outputId": "ae71b38b-b9a4-4697-8881-cc3a38e42efd"
   },
   "outputs": [],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jfD890PHqD9c",
   "metadata": {
    "id": "jfD890PHqD9c"
   },
   "source": [
    "* GBM is the top performer, reliable and stable across folds.\n",
    "* AdaBoost is a close second, great if you care more about minimizing false negatives.\n",
    "* XGBoost is also strong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fYLfDmHvbp1B",
   "metadata": {
    "id": "fYLfDmHvbp1B"
   },
   "source": [
    "### Model Building with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TstCnqXpg7qk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TstCnqXpg7qk",
    "outputId": "1c7ec8f4-dd3f-4ae6-fa6c-450f11b758f5"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "\n",
    "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_un == 1)))\n",
    "print(\"After UnderSampling, counts of label '0': {} \\n\".format(sum(y_train_un == 0)))\n",
    "\n",
    "\n",
    "print(\"After UnderSampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
    "print(\"After UnderSampling, the shape of train_y: {} \\n\".format(y_train_un.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8gP3FxAig9nQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gP3FxAig9nQ",
    "outputId": "c6c4f588-2ad1-4e46-bda6-4dc7299fc4f1"
   },
   "outputs": [],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "\n",
    "results1 = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  ## set the number of splits\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_un, y=y_train_un,scoring = scorer, cv=kfold,n_jobs =-1\n",
    "    )\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_un, y_train_un) ## fit the model on the undersampled data.\n",
    "    scores = f1_score(y_val, model.predict(X_val)) ## define the metric function name.\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4tjrKF8jhnly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "4tjrKF8jhnly",
    "outputId": "29744a02-548d-4c38-8db3-55660b4b6e3b"
   },
   "outputs": [],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j8L59vA5qYbO",
   "metadata": {
    "id": "j8L59vA5qYbO"
   },
   "source": [
    "* GBM remains the most robust across evaluation metrics.\n",
    "* AdaBoost is consistently strong.\n",
    "* XGBoost maintains good performance.\n",
    "* Decision Tree underperforms across the board.\n",
    "* Bagging struggles with consistency and recall/precision trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cg_OREBD1NOy",
   "metadata": {
    "id": "Cg_OREBD1NOy"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2FtmPS7Ubp1D",
   "metadata": {
    "id": "2FtmPS7Ubp1D"
   },
   "source": [
    "### Tuning AdaBoost using oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mQpzS03MkhcV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQpzS03MkhcV",
    "outputId": "18fe2da0-95c3-4fc4-e349-bae8fea38131"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# defining model\n",
    "Model = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150], ## set the number of estimators\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1], ## set the learning rate.\n",
    "    \"estimator\": [\n",
    "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
    "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    n_jobs = -1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1)\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over) ## fit the model on over sampled data\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1Vza4LcWortx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "1Vza4LcWortx",
    "outputId": "459314bf-c1ea-4d47-e0d3-76b06b961022"
   },
   "outputs": [],
   "source": [
    "## set the best parameters.\n",
    "tuned_ada = AdaBoostClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, estimator= DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    ")\n",
    "\n",
    "tuned_ada.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bx4schyuo6Sk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "bx4schyuo6Sk",
    "outputId": "138cc66a-aa49-4550-8875-445ee0228112"
   },
   "outputs": [],
   "source": [
    "ada_train_perf = model_performance_classification_sklearn(tuned_ada, X_train_over, y_train_over)\n",
    "ada_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6TVkF0oJo8Jx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "6TVkF0oJo8Jx",
    "outputId": "e8b94dfc-f28e-4c2a-c84a-2462c9676a1d"
   },
   "outputs": [],
   "source": [
    "ada_val_perf = model_performance_classification_sklearn(tuned_ada, X_val, y_val)\n",
    "ada_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dqj6dc38bp1E",
   "metadata": {
    "id": "Dqj6dc38bp1E"
   },
   "source": [
    "### Tuning Random forest using undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eH00gEgWpqzt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eH00gEgWpqzt",
    "outputId": "88cf1891-25b2-4662-a8d3-4332b535ef00"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# defining model\n",
    "Model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"min_samples_leaf\": np.arange(1, 5),\n",
    "    \"max_features\": [np.arange(1, 10, 2), 'sqrt'],\n",
    "    \"max_samples\": np.arange(0.5, 1.0, 0.1)\n",
    "}\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_un, y_train_un)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dnRAsKqJSE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70dnRAsKqJSE",
    "outputId": "2f6b7683-cc8e-4bf2-b8e9-8a20cf3ca4e2"
   },
   "outputs": [],
   "source": [
    "tuned_rf2 = RandomForestClassifier(\n",
    "    max_features='sqrt',\n",
    "    random_state=1,\n",
    "    max_samples=0.5,\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=4,\n",
    ")\n",
    "\n",
    "tuned_rf2.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tqEmuqnnqYf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqEmuqnnqYf4",
    "outputId": "19004130-6d7d-45cc-91d0-9e31e49b351c"
   },
   "outputs": [],
   "source": [
    "rf2_train_perf = model_performance_classification_sklearn(\n",
    "    tuned_rf2, X_train_un, y_train_un\n",
    ")\n",
    "rf2_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RJZzZP62qdWy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJZzZP62qdWy",
    "outputId": "570d4673-49fc-4c3d-e569-7e295a3efbf3"
   },
   "outputs": [],
   "source": [
    "rf2_val_perf = model_performance_classification_sklearn(\n",
    "    tuned_rf2, X_val, y_val\n",
    ")\n",
    "rf2_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0uLE_tPV2Roq",
   "metadata": {
    "id": "0uLE_tPV2Roq"
   },
   "source": [
    "### Tuning with Gradient boosting with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H64uZ65hrFoc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H64uZ65hrFoc",
    "outputId": "fe0f71b7-3050-4772-db49-2a5f5a38a329"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# defining model\n",
    "Model = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(50, 200, 50),\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"subsample\": [0.7, 1.0],\n",
    "    \"max_features\": ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    scoring=scorer,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wn2cr48RrOmA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wn2cr48RrOmA",
    "outputId": "438f0d94-5fb9-44fd-96ca-6051be66186c"
   },
   "outputs": [],
   "source": [
    "tuned_gbm = GradientBoostingClassifier(\n",
    "    max_features='sqrt',\n",
    "    random_state=1,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=150,\n",
    "    subsample=1.0\n",
    ")\n",
    "\n",
    "tuned_gbm.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vVGbKmourR8M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVGbKmourR8M",
    "outputId": "dd911dd5-2b09-413d-b993-1c4b8e930764"
   },
   "outputs": [],
   "source": [
    "gbm_train_perf = model_performance_classification_sklearn(\n",
    "    tuned_gbm, X_train_over, y_train_over\n",
    ")\n",
    "gbm_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "es3Jov5YrYQA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "es3Jov5YrYQA",
    "outputId": "dc9fae3c-0d14-49e9-8d9a-4f580489df0e"
   },
   "outputs": [],
   "source": [
    "## print the model performance on the validation data.\n",
    "gbm_val_perf = model_performance_classification_sklearn(tuned_gbm, X_val, y_val)\n",
    "gbm_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VbrQHwrKbp1C",
   "metadata": {
    "id": "VbrQHwrKbp1C"
   },
   "source": [
    "### Tuning XGBoost using oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icVqSGqOsdK0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icVqSGqOsdK0",
    "outputId": "6ada7f64-5806-401a-cbde-2a92a36837bf"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# defining model\n",
    "Model = XGBClassifier(random_state=1,eval_metric='logloss')\n",
    "\n",
    "## define the hyperparameters\n",
    "param_grid={\n",
    "    'n_estimators':[100, 200, 300],\n",
    "    'scale_pos_weight':[1, 2, 5],\n",
    "    'learning_rate':[0.01, 0.05, 0.1],\n",
    "    'gamma':[0, 1, 5],\n",
    "    'subsample':[0.7, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "## Set the cv parameter\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    n_jobs = -1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1\n",
    "    )\n",
    "\n",
    "#Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over,y_train_over)\n",
    "\n",
    "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilxn8Y7qtS_X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilxn8Y7qtS_X",
    "outputId": "bdf0e86e-9442-4ebd-9476-fb3d9f5add41"
   },
   "outputs": [],
   "source": [
    "## Code to define the best model\n",
    "xgb2 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    eval_metric='logloss',\n",
    "    subsample=1.0,\n",
    "    scale_pos_weight=2,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    gamma=1,\n",
    ")\n",
    "\n",
    "xgb2.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CmcmdnBlxO1Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "CmcmdnBlxO1Y",
    "outputId": "a953c95e-7390-4b04-9e6d-c0b9390c7479"
   },
   "outputs": [],
   "source": [
    "xgb2_train_perf = model_performance_classification_sklearn(\n",
    "    xgb2, X_train_over, y_train_over\n",
    ")\n",
    "xgb2_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nKys1SKSxVdK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "nKys1SKSxVdK",
    "outputId": "b41b0f59-3ab6-4657-b234-2b304e1eef71"
   },
   "outputs": [],
   "source": [
    "## Model performance on the validation data.\n",
    "xgb2_val_perf = model_performance_classification_sklearn(xgb2, X_val, y_val)\n",
    "xgb2_val_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fyp5xd91Z-W",
   "metadata": {
    "id": "4fyp5xd91Z-W"
   },
   "source": [
    "**We have now tuned all the models, let's compare the performance of all tuned models and see which one is the best.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D9JNnpxa4jau",
   "metadata": {
    "id": "D9JNnpxa4jau"
   },
   "source": [
    "## Model performance comparison and choosing the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S6tMn-PKxqO4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "S6tMn-PKxqO4",
    "outputId": "b791882a-dc37-4ee2-ed4c-12292e971252"
   },
   "outputs": [],
   "source": [
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        gbm_train_perf.T,\n",
    "        xgb2_train_perf.T,\n",
    "        ada_train_perf.T,\n",
    "        rf2_train_perf.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Gradient Boosting tuned with oversampled data\",\n",
    "    \"XGBoost tuned with oversampled data\",\n",
    "    \"AdaBoost tuned with oversampled data\",\n",
    "    \"Random forest tuned with undersampled data\",\n",
    "]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fh4R80EXxvjq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "Fh4R80EXxvjq",
    "outputId": "95a6ba61-ad0c-4248-b10f-ea06521323ce"
   },
   "outputs": [],
   "source": [
    "# validation performance comparison\n",
    "\n",
    "models_val_comp_df = pd.concat(\n",
    "    [\n",
    "        gbm_val_perf.T,\n",
    "        xgb2_val_perf.T,\n",
    "        ada_val_perf.T,\n",
    "        rf2_val_perf.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_val_comp_df.columns = [\n",
    "    \"Gradient Boosting tuned with oversampled data\",\n",
    "    \"XGBoost tuned with oversampled data\",\n",
    "    \"AdaBoost tuned with oversampled data\",\n",
    "    \"Random forest tuned with undersampled data\",\n",
    "]\n",
    "print(\"Validation performance comparison:\")\n",
    "models_val_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qPrtDa9uF8YO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "qPrtDa9uF8YO",
    "outputId": "6b52ada5-1101-43c9-ed05-a31f7f61e669"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Model performance data\n",
    "data = {\n",
    "    \"Metric\": [\"Accuracy\", \"Recall\", \"Precision\", \"F1\"],\n",
    "    \"Gradient Boosting (Over)\": [0.740369, 0.845233, 0.783179, 0.813023],\n",
    "    \"XGBoost (Over)\": [0.725105, 0.948629, 0.724763, 0.821722],\n",
    "    \"AdaBoost (Over)\": [0.739642, 0.841315, 0.784453, 0.811890],\n",
    "    \"Random Forest (Under)\": [0.708533, 0.722682, 0.819551, 0.768074]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set 'Metric' as index\n",
    "df.set_index(\"Metric\", inplace=True)\n",
    "\n",
    "# Plot grouped bar chart\n",
    "df.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Model Comparison Across Metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.65, 1.0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"y\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80nDBu0JfoHo",
   "metadata": {
    "id": "80nDBu0JfoHo"
   },
   "source": [
    "**Best Overall (F1 Score):**\n",
    "**XGBoost (Oversampled)** has the highest F1 score (0.822) and recall (0.949), making it the best model when you want to catch as many positives as possible (e.g. maximize visa certification prediction).\n",
    "\n",
    "**Best Precision:**\n",
    "**Random Forest (Undersampled)** has the highest precision (0.820) — good if you want to avoid false positives (e.g. avoid certifying unlikely cases).\n",
    "\n",
    "**Most Balanced:**\n",
    "**Gradient Boosting (Oversampled)** is a solid all-around choice with good precision and recall — a safe default if you want balanced performance without extremes.\n",
    "\n",
    "**Final Pick**\n",
    "Use **XGBoost (Oversampled)** considering recall as the priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tlodjQGzxx2F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "tlodjQGzxx2F",
    "outputId": "8049253c-ff13-44f8-b46b-3fabc2e8c428"
   },
   "outputs": [],
   "source": [
    "## print the model performance on the test data by the best model.\n",
    "test = model_performance_classification_sklearn(xgb2, X_test, y_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g7kMEMJCyjoB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7kMEMJCyjoB",
    "outputId": "0b1c824f-c939-40a5-bf10-3b5b5bd553ac"
   },
   "outputs": [],
   "source": [
    "## print the feature importances from the best model.\n",
    "feature_names = X_train.columns\n",
    "importances = xgb2.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-knock",
   "metadata": {
    "id": "congressional-knock"
   },
   "source": [
    "## Actionable Insights and Recommendations\n",
    "\n",
    "**Top Predective Features**\n",
    "* education_of_employee_Bachelor's\n",
    "* has_job_experience_N\n",
    "* education_of_employee_Doctorate\n",
    "* education_of_employee_Master's\n",
    "* has_job_experience_Y\n",
    "\n",
    "**Education level and job experience are the most important predictors for visa approval**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T9Y1eN57yzjb",
   "metadata": {
    "id": "T9Y1eN57yzjb"
   },
   "source": [
    "* Higher education (Master’s) and experience increase certification chances.\n",
    "* Region matters: South > Northeast for approvals.\n",
    "* Higher wage offers correlate with approvals (~$7K more median)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-RqR06thzC9Z",
   "metadata": {
    "id": "-RqR06thzC9Z"
   },
   "source": [
    "1. Prioritize Experienced Applicants.\n",
    "* Insight: Lack of job experience is a key differentiator in denied cases.\n",
    "* Recommendation: Encourage applicants to gain relevant work experience before applying or emphasize their existing experience in the application.\n",
    "\n",
    "2. Target Candidates with Higher Education\n",
    "* Insight: Master’s degree holders have a higher success rate than Bachelor’s degree holders.\n",
    "* Recommendation: Prioritize or recommend applicants with Master’s or higher degrees, especially in STEM or in-demand fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y2HdXLmSJi8K",
   "metadata": {
    "id": "Y2HdXLmSJi8K"
   },
   "source": [
    "<font size=6 color='blue'>Power Ahead</font>\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
